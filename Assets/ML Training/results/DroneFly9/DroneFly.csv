Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
5000,1.4185934,33.28767123287671,-1.1262388,0.0006206896412989189,0.0006206896412989189,17.457523,0.24189004,0.00029962818,0.19987606,0.00049939274,1.0
10000,1.3995769,34.785714285714285,0.0009058506,0.0007142856983201844,0.0007142856983201844,0.0011875961,0.24785879,0.0002988803,0.19962679,0.0004981712,1.0
15000,1.381569,49.57575757575758,0.014790771,0.0005050504937617466,0.0005050504937617466,0.014891227,0.22787523,0.00029812526,0.19937508,0.0004969379,1.0
20000,1.3542259,62.31645569620253,0.015109438,0.0,0.0,0.053781476,0.24917345,0.00029735986,0.19911994,0.00049568777,1.0
25000,1.3428174,48.91,0.091775894,0.0,0.0,0.16247284,0.24568477,0.00029663296,0.19887765,0.0004945005,1.0
30000,1.3210721,46.80952380952381,-0.028130297,0.0,0.0,0.04828117,0.2518924,0.00029587332,0.19862445,0.00049325975,1.0
35000,1.3041636,46.97115384615385,0.044181354,0.0,0.0,0.023257194,0.24617116,0.000295125,0.19837499,0.00049203756,1.0
40000,1.2839986,46.41904761904762,-0.003285917,0.0,0.0,0.05545546,0.2436314,0.00029437727,0.19812576,0.0004908162,1.0
45000,1.2808688,47.375,-0.004393085,0.0,0.0,0.0014480212,0.25182235,0.00029361903,0.197873,0.00048957765,1.0
50000,1.2765551,47.37864077669903,0.0466941,0.0,0.0,0.040691007,0.24625394,0.000292882,0.19762732,0.000488374,1.0
55000,1.2353743,47.01923076923077,-0.00024051018,0.0,0.0,0.02135869,0.25216383,0.0002921323,0.19737743,0.00048714946,1.0
60000,1.2077308,48.049019607843135,0.0017502916,0.0,0.0,0.018829519,0.24090943,0.00029137044,0.19712348,0.00048590507,1.0
65000,1.2160374,51.25,0.051683586,0.0,0.0,0.03208787,0.24013026,0.00029060766,0.19686922,0.00048465913,1.0
70000,1.2096558,53.38461538461539,-0.019854154,0.0,0.0,0.035887424,0.23733598,0.00028988376,0.1966279,0.00048347673,1.0
